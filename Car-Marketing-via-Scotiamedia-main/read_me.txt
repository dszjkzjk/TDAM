final project:

Please follow the order:

1. twitter scraping.py: using Twitter API to scrap tweets output ua1.csv

2. ua1.csv: data 

3. part2.py: preprocessing ua1.csv to generate two data set df3.csv and df_final.csv.

4. df_final.csv: for drawing network using NetworkX and calculate betweeness, closeness etc.  

5. df3.csv: data contain every information for finding top influencers

6. find_top_influ.py: using df3.csv and instructions in assignment 1 to get top 100 influencers in luxury cars network.

7. top_100.csv: generated by step 6.

8. top_100_user.csv : manually labeled each user with relativity of luxury cars topic.

9. top_influencer_scraping.py: scrap at most 50 tweets from top 10 user in top_100_user.csv 
with 'related' column = Yes, contain # 0f comments/likes/retweets and url of pictures in each tweet,
output url_file.csv.

10: google_api.py: using google vision to tag each picture, output google_tags.csv.

11. google_tags_model.py: build model to predict engagement level, predictor is google tag. 

12.  lda.py: splited google_tags.csv to top 25 and bottom 25 based on engagement scores,
then applying lda to find topic distribution, output: top_dist.csv to see positive and negative impact of each topic (by comparing topic distribution in top_25_per.csv and bottom_25_per.csv).

13. top25_per.csv and bottom25_per.csv: mentioned in step 12.

14. topic_dist.csv: mentioned in step 12.

 